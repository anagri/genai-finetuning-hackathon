{"instruction": "Using the python langchain library, parse the output of language model for a joke including setup and punchline fields by creating a custom pydantic class.", "input": "", "output": "from typing import Optional, List\nfrom pydantic import BaseModel, Field\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.output_parsers import PydanticOutputParser\n\n# Pydantic data class\nclass JokeSchema(BaseModel):\n    setup: str = Field(description=\"setup of the joke\")\n    punchline: str = Field(description=\"punchline of the joke\")\n    \n# Parser\nparser = PydanticOutputParser(pydantic_object=JokeSchema)\n\n# Prompt\nprompt = PromptTemplate(\n    template=\"Tell a joke.\\n{format_instructions}\\n\",\n    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n)\n\n# Run model\njoke_query = \"Tell me a joke.\"\n_input = prompt.format_prompt(query=joke_query)\nmodel = OpenAI(temperature=0)\noutput = model(_input.to_string())\nparser.parse(output)"}
{"instruction": "Using the python langchain library and the previously initialized GPT4All LLM, run a LLMChain operation using a PromptTemplate and retrieve documents.", "input": "", "output": "from langchain import PromptTemplate, LLMChain\n\nprompt = PromptTemplate.from_template(\n    \"What are the main concepts in the retrieved document: {docs}\"\n)\nllm_chain = LLMChain(llm=llm, prompt=prompt)\n\nquestion = \"Discuss Deep Learning architectures\"\ndocs = vectorstore.similarity_search(question)\nresult = llm_chain(docs)\n\nresult[\"text\"]"}
{"instruction": "Using the python langchain library, make use of Pydantic schema to specify the required properties and types for tagging a given text.", "input": "", "output": "from langchain.chat_models import ChatOpenAI\nfrom langchain.chains import create_tagging_chain_pydantic\nfrom pydantic import BaseModel, Field\n\nclass Tags(BaseModel):\n    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n    language: str = Field(..., enum=[\"english\", \"french\", \"german\", \"italian\", \"spanish\"])\n\n# LLM\nllm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\nchain = create_tagging_chain_pydantic(Tags, llm)\n\ninp = \"Je suis très content de t'avoir rencontré! Je pense que nous serons de très bons amis!\"\nresult = chain.run(inp)\nprint(result)"}
{"instruction": "Using the python langchain library, create a chat interface using a plain chat model that will respond to a user message.", "input": "", "output": "from langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage\n)\nfrom langchain.chat_models import ChatOpenAI\n\nchat = ChatOpenAI()\nchat([HumanMessage(content=\"Translate this sentence from English to French: I love programming.\")])"}
{"instruction": "Use python's langchain library to index document chunks using a vector store.", "input": "", "output": "from langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\n# Assuming 'source_chunks' is a list of document chunks\nsearch_index = Chroma.from_documents(source_chunks, OpenAIEmbeddings())"}
