{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import builtins\n",
    "from getpass import getpass\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = \"\"\"Do the following tasks referring the the use case document-\n",
    "1. Analyze the use case and understand the workings of langchain library\n",
    "2. Using the prompt format below, generate 10 sample prompts replacing the external non-langchain entities or resources like urls mentioned in the documentation with a similar entities or resources covering the features that langchain offers\n",
    "3. The prompt format has 2 sections Instructions and Response\n",
    "4. In the instructions, detail the task you are trying to accomplish using langchain\n",
    "5. In the response, write the code that you would write to accomplish the task\n",
    "6. Separate each prompt with a line break\n",
    "7. follow the prompt format religiously\n",
    "\n",
    "prompt format:\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/amir36/Documents/workspace/src/github.com/anagri/genai-finetuning-hackathon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"use-cases-md/multiple_retrieval.md\",\n",
    "    \"use-cases-md/tagging.md\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing use-case: use-cases-md/multiple_retrieval.md\n",
      "generated 2 prompts\n",
      "processing use-case: use-cases-md/tagging.md\n",
      "generated 9 prompts\n"
     ]
    }
   ],
   "source": [
    "# read all files from use-cases-md\n",
    "import glob\n",
    "\n",
    "# files = glob.glob(\"use-cases-md/*.md\")\n",
    "\n",
    "for file in files:\n",
    "    print(f\"processing use-case: {file}\")\n",
    "    doc = open(file, \"r\").read()\n",
    "    # split file into name and extension\n",
    "    filename = os.path.basename(file)\n",
    "    name, _ = os.path.splitext(filename)\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert programmer.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Below is the usage for the python library langchain.\"\n",
    "                \"langchain is used to interact with Large Language Models and accomplish a variety of tasks. \"\n",
    "                \"The code below covers how to use langchain library to make API calls\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": doc},\n",
    "            {\"role\": \"user\", \"content\": generation_prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = completion.choices[0].message[\"content\"]\n",
    "    examples = response.split(\"---\")\n",
    "    examples = [e.strip() for e in examples]\n",
    "    examples = [e for e in examples if len(e) > 0]\n",
    "    print(f\"generated {len(examples)} prompts\")\n",
    "    for i, ex in enumerate(examples):\n",
    "        with builtins.open(f\"{base_dir}/training-data/{name}-{i}.md\", \"w\") as f:\n",
    "            f.write(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_inst = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all files from training-data, if the first line of file is not as given, insert the line into the file\n",
    "files = glob.glob(\"training-data/*.md\")\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line != start_inst:\n",
    "            with open(file, \"r+\") as f:\n",
    "                content = f.read()\n",
    "                f.seek(0, 0)\n",
    "                f.write(start_inst+ \"\\n\\n\" + content)\n",
    "        else:\n",
    "            print(f\"file {file} is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
